{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Instructions for This Notebook\n",
    "- **Cells 2-20:** For local use only (embedding generation, upsert to Pinecone, etc.). These require a lot of memory and are not suitable for Render or low-memory environments.\n",
    "- **For deployment (Render):** Only use Pinecone for retrieval and Groq for answering. Do not run embedding or torch-related cells in production.\n",
    "- **See the last cell for a lightweight retrieval/QA example suitable for Render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nipun\\Desktop\\LLmplusrag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob=\"*.pdf\",\n",
    "                            loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory not found: 'Data/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m extracted_data\u001b[38;5;241m=\u001b[39m\u001b[43mload_pdf_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 6\u001b[0m, in \u001b[0;36mload_pdf_file\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_pdf_file\u001b[39m(data):\n\u001b[0;32m      2\u001b[0m     loader\u001b[38;5;241m=\u001b[39m DirectoryLoader(data,\n\u001b[0;32m      3\u001b[0m                             glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m                             loader_cls\u001b[38;5;241m=\u001b[39mPyPDFLoader)\n\u001b[1;32m----> 6\u001b[0m     documents\u001b[38;5;241m=\u001b[39m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m documents\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\document_loaders\\directory.py:117\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\document_loaders\\directory.py:123\u001b[0m, in \u001b[0;36mDirectoryLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m p \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory not found: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected directory, got file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Directory not found: 'Data/'"
     ]
    }
   ],
   "source": [
    "extracted_data=load_pdf_file(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 1063\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nipun\\AppData\\Local\\Temp\\ipykernel_24612\\1196424635.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "c:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"Groq API Key is missing. Set it in the .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'medbot' is ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "# Get Pinecone API key from environment\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"Pinecone API Key is missing. Set it in the .env file.\")\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Define the index name\n",
    "index_name = \"medbot\"\n",
    "\n",
    "# Create the index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # Adjust based on your embeddings\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"Index '{index_name}' is ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "# Ensure PyTorch uses GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the embedding model and move it to GPU\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\")\n",
    "\n",
    "# Custom embedding class for LangChain compatibility\n",
    "class CustomEmbeddings(Embeddings):\n",
    "    def embed_documents(self, texts):\n",
    "        with torch.no_grad():\n",
    "            return embedding_model.encode(texts, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.embed_documents([text])[0]\n",
    "\n",
    "# Instantiate the custom embedding class\n",
    "embedding_instance = CustomEmbeddings()\n",
    "\n",
    "# Batch processing for Pinecone upsert\n",
    "batch_size = 1000  # Adjust as needed\n",
    "for i in range(0, len(text_chunks), batch_size):\n",
    "    docsearch = PineconeVectorStore.from_documents(\n",
    "        documents=text_chunks[i:i+batch_size],\n",
    "        index_name=index_name,\n",
    "        embedding=embedding_instance  # Use the instance, not a function\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing index \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x29dcdc983b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is TIme complexity?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='3b5f9cdc-1850-40e5-82db-afa1d0960e44', metadata={'author': 'EDGE Note', 'creationdate': '2009-08-20T02:28:03-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2009-08-20T02:28:03-05:00', 'page': 979.0, 'page_label': '980', 'producer': 'Acrobat Distiller 9.0.0 (Windows)', 'source': 'Data\\\\Medical_book.pdf', 'title': 'Principles of internal medicine', 'total_pages': 5113.0}, page_content='neoplasm is malignant. Cancer is a synonym for malignant neoplasm. Cancers of \\nepithelial tissues are called carcinomas; cancers of nonepithelial (mesenchymal) tissues \\nare called sarcomas.\\nCancer is a genetic disease, but the level of its expression is the single cell. Although \\nsome forms of cancer are heritable, most mutations occur in somatic cells and are \\ncaused by intrinsic errors in DNA replication or are induced by carcinogen exposure. A'),\n",
       " Document(id='7d52f22a-2213-423a-a4fb-0c5e9333b9aa', metadata={'author': 'EDGE Note', 'creationdate': '2009-08-20T02:28:03-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2009-08-20T02:28:03-05:00', 'page': 979.0, 'page_label': '980', 'producer': 'Acrobat Distiller 9.0.0 (Windows)', 'source': 'C:\\\\Users\\\\LENOVO\\\\PycharmProjects\\\\MedBot\\\\Data\\\\Medical_book.pdf', 'title': 'Principles of internal medicine', 'total_pages': 5113.0}, page_content='neoplasm is malignant. Cancer is a synonym for malignant neoplasm. Cancers of \\nepithelial tissues are called carcinomas; cancers of nonepithelial (mesenchymal) tissues \\nare called sarcomas.\\nCancer is a genetic disease, but the level of its expression is the single cell. Although \\nsome forms of cancer are heritable, most mutations occur in somatic cells and are \\ncaused by intrinsic errors in DNA replication or are induced by carcinogen exposure. A'),\n",
       " Document(id='c84e7d7c-869e-4f5e-b3ee-3d080181cda3', metadata={'author': 'EDGE Note', 'creationdate': '2009-08-20T02:28:03-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2009-08-20T02:28:03-05:00', 'page': 979.0, 'page_label': '980', 'producer': 'Acrobat Distiller 9.0.0 (Windows)', 'source': 'Data\\\\Medical_book.pdf', 'title': 'Principles of internal medicine', 'total_pages': 5113.0}, page_content='neoplasm is malignant. Cancer is a synonym for malignant neoplasm. Cancers of \\nepithelial tissues are called carcinomas; cancers of nonepithelial (mesenchymal) tissues \\nare called sarcomas.\\nCancer is a genetic disease, but the level of its expression is the single cell. Although \\nsome forms of cancer are heritable, most mutations occur in somatic cells and are \\ncaused by intrinsic errors in DNA replication or are induced by carcinogen exposure. A')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Set API key directly\n",
    "api_key = \"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\"\n",
    "\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0.4, max_tokens=500, api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a DSA assistant. For every question or code input, only provide the time complexity of the code in your answer. \"\n",
    "    \"Do not provide space complexity, explanations, or any other information. \"\n",
    "    \"Output only the time complexity in standard notation (e.g., O(n), O(1), O(n^2)). \"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the question-answering chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Assume `retriever` is already defined elsewhere\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: O(1)\n"
     ]
    }
   ],
   "source": [
    "# RAG + LLM QA Example\n",
    "question = \"Print(hello world)   ?\"\n",
    "\n",
    "response = rag_chain.invoke({\"input\": question})\n",
    "\n",
    "print(\"Answer:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Embedding must be provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedbot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m pc \u001b[38;5;241m=\u001b[39m Pinecone(api_key\u001b[38;5;241m=\u001b[39mPINECONE_API_KEY)\n\u001b[1;32m---> 14\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mPineconeVectorStore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# No embedding model needed at runtime\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpinecone_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPINECONE_API_KEY\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m groq_llm \u001b[38;5;241m=\u001b[39m ChatGroq(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixtral-8x7b-32768\u001b[39m\u001b[38;5;124m\"\u001b[39m, api_key\u001b[38;5;241m=\u001b[39mGROQ_API_KEY)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# System prompt specialized for rainwater harvesting, but allows any question\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_pinecone\\vectorstores.py:187\u001b[0m, in \u001b[0;36mPineconeVectorStore.__init__\u001b[1;34m(self, index, embedding, text_key, namespace, distance_strategy, pinecone_api_key, index_name)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# setting default params to bypass having to pass in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m     index_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    185\u001b[0m ):\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding must be provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding \u001b[38;5;241m=\u001b[39m embedding\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m text_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Embedding must be provided"
     ]
    }
   ],
   "source": [
    "# # Lightweight Retrieval/QA Example for Render (No Embedding Model, No torch)\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from langchain_pinecone import PineconeVectorStore\n",
    "# from langchain_groq import ChatGroq\n",
    "# from langchain.chains import RetrievalQA\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from pinecone import Pinecone\n",
    "# load_dotenv()\n",
    "# PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "# GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "# index_name = \"medbot\"\n",
    "# pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "# vector_store = PineconeVectorStore(\n",
    "#     index_name=index_name,\n",
    "#     embedding=None,  # No embedding model needed at runtime\n",
    "#     pinecone_api_key=PINECONE_API_KEY\n",
    "# )\n",
    "# groq_llm = ChatGroq(model_name=\"mixtral-8x7b-32768\", api_key=GROQ_API_KEY)\n",
    "# # System prompt specialized for rainwater harvesting, but allows any question\n",
    "# system_prompt = (\n",
    "#     \"You are an assistant specialized in rainwater harvesting and related topics. \"+\n",
    "#     \"Use the provided context to answer user questions as thoroughly as possible. \"+\n",
    "#     \"If the answer is not in the context, say you don't know.\\n\\n{context}\"\n",
    "# )\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", system_prompt),\n",
    "#     (\"human\", \"{input}\"),\n",
    "# ])\n",
    "# retriever = vector_store.as_retriever()\n",
    "# qa_chain = RetrievalQA.from_chain_type(llm=groq_llm, retriever=retriever, prompt=prompt)\n",
    "# response = qa_chain.invoke({\"query\": \"How do I implement rainwater harvesting on my rooftop in Rajasthan?\"})\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightweight Rainwater Harvesting RAG QA (for Render/Production)\n",
    "This cell demonstrates how to use your Pinecone index and Groq LLM to answer questions about rainwater harvesting (or any topic covered in your indexed documents).\n",
    "- The bot is specialized for rainwater harvesting, but you can ask any question.\n",
    "- No embedding model or torch is used at runtime—suitable for Render and low-memory environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
